"""ì›¹ ê²€ìƒ‰ ë„êµ¬ (Tavily + Serper.dev Fallback + Redis ìºì‹±)"""

import os
import hashlib
import re
import asyncio
import aiohttp
from typing import List, Dict, Any, Optional, Set
from tavily import TavilyClient
from dotenv import load_dotenv
from app.tools.cache import research_cache

# .env íŒŒì¼ ë¡œë“œ (ëª¨ë“ˆ ì´ˆê¸°í™” ì‹œì ì— í•„ìš”)
load_dotenv()


class SearchWithFallback:
    """Tavily ìš°ì„ , ì‹¤íŒ¨ ì‹œ Serper.dev Fallback"""
    
    def __init__(self, tavily_api_key: Optional[str] = None, serper_api_key: Optional[str] = None):
        self.tavily_api_key = tavily_api_key or os.getenv("TAVILY_API_KEY")
        self.serper_api_key = serper_api_key or os.getenv("SERPER_API_KEY")
        
        self.tavily = None
        if self.tavily_api_key and self.tavily_api_key != "tvly-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx":
            try:
                self.tavily = TavilyClient(api_key=self.tavily_api_key)
            except Exception as e:
                pass  # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ Serper ì‚¬ìš©
    
    async def search(
        self, 
        query: str, 
        max_results: int = 5,
        search_depth: str = "advanced",
        enable_verification: bool = True
    ) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì‹¤í–‰ (Redis ìºì‹± â†’ ë™ì  ê¹Šì´ ì¡°ì • â†’ êµì°¨ ê²€ì¦)"""
        
        # 0ì°¨: Redis ìºì‹œ í™•ì¸ (ê²€ìƒ‰ ì¿¼ë¦¬ ìºì‹±)
        cached_result = research_cache.get(query, domain="search", prefix="query")
        if cached_result:
            return cached_result
        
        # ë™ì  ê¹Šì´ ì¡°ì •: basic â†’ intermediate â†’ advanced
        # ì²« ê²€ìƒ‰ì€ basicìœ¼ë¡œ ë¹ ë¥´ê²Œ ì‹œì‘
        initial_depth = "basic"
        initial_max_results = min(max_results, 3)  # ì²« ê²€ìƒ‰ì€ 3ê°œë§Œ
        
        # êµì°¨ ê²€ì¦ í™œì„±í™” ì‹œ: Tavily + Serper Fallback
        if enable_verification and self.tavily:
            return await self._search_with_verification_dynamic(
                query, max_results, search_depth, initial_depth, initial_max_results
            )
        
        # êµì°¨ ê²€ì¦ ë¹„í™œì„±í™”: ë™ì  ê¹Šì´ ì¡°ì •
        if self.tavily:
            result = await self._search_tavily_dynamic(
                query, max_results, search_depth, initial_depth, initial_max_results
            )
            if result["success"]:
                research_cache.set(query, result, domain="search", prefix="query")
                return result
        
        # Serper Fallback
        serper_result = await self._search_serper(query, initial_max_results)
        if serper_result.get("success"):
            research_cache.set(query, serper_result, domain="search", prefix="query")
            return serper_result
        
        # ê²°ê³¼ ë¶€ì¡± ì‹œ max_results í™•ì¥í•˜ì—¬ ì¬ì‹œë„
        if initial_max_results < max_results:
            serper_result = await self._search_serper(query, max_results)
            if serper_result.get("success"):
                research_cache.set(query, serper_result, domain="search", prefix="query")
                return serper_result
        
        return serper_result
    
    async def _search_with_verification_dynamic(
        self,
        query: str,
        max_results: int,
        target_depth: str,
        initial_depth: str,
        initial_max_results: int
    ) -> Dict[str, Any]:
        """ë™ì  ê¹Šì´ ì¡°ì •: basic â†’ intermediate â†’ advanced"""
        print(f"ğŸ” [ê²€ìƒ‰] Tavily ìš°ì„  ê²€ìƒ‰ (ë™ì  ê¹Šì´): {query}")
        
        # 1ë‹¨ê³„: basicìœ¼ë¡œ ë¹ ë¥´ê²Œ ì‹œë„
        tavily_result = await self._search_tavily(query, initial_max_results, initial_depth)
        
        if tavily_result.get("success"):
            # ê²°ê³¼ê°€ ì¶©ë¶„í•˜ë©´ ë°”ë¡œ ë°˜í™˜
            if len(tavily_result.get("results", [])) >= 2:
                print(f"âœ… [Tavily] ì¶©ë¶„í•œ ê²°ê³¼ í™•ë³´ (basic, {len(tavily_result['results'])}ê°œ)")
                research_cache.set(query, tavily_result, domain="search", prefix="query")
                return tavily_result
        
        # 2ë‹¨ê³„: ê²°ê³¼ ë¶€ì¡± ì‹œ intermediateë¡œ ì¬ì‹œë„
        if initial_depth == "basic" and target_depth in ["intermediate", "advanced"]:
            print(f"âš ï¸ [Tavily] basic ê²°ê³¼ ë¶€ì¡±, intermediateë¡œ ì¬ì‹œë„...")
            tavily_result = await self._search_tavily(query, max_results, "intermediate")
            
            if tavily_result.get("success") and len(tavily_result.get("results", [])) >= 2:
                print(f"âœ… [Tavily] ì¶©ë¶„í•œ ê²°ê³¼ í™•ë³´ (intermediate, {len(tavily_result['results'])}ê°œ)")
                research_cache.set(query, tavily_result, domain="search", prefix="query")
                return tavily_result
        
        # 3ë‹¨ê³„: ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ advancedë¡œ ì¬ì‹œë„
        if target_depth == "advanced":
            print(f"âš ï¸ [Tavily] intermediate ê²°ê³¼ ë¶€ì¡±, advancedë¡œ ì¬ì‹œë„...")
            tavily_result = await self._search_tavily(query, max_results, "advanced")
            
            if tavily_result.get("success"):
                print(f"âœ… [Tavily] ê²°ê³¼ í™•ë³´ (advanced, {len(tavily_result.get('results', []))}ê°œ)")
                research_cache.set(query, tavily_result, domain="search", prefix="query")
                return tavily_result
        
        # Tavily ì‹¤íŒ¨ ì‹œì—ë§Œ Serper ì‹œë„
        print(f"âš ï¸ [Tavily] ì‹¤íŒ¨, Serper.dev ì‹œë„...")
        serper_result = await self._search_serper(query, max_results)
        
        if serper_result.get("success"):
            print(f"âœ… [Serper] ê²°ê³¼ í™•ë³´")
            research_cache.set(query, serper_result, domain="search", prefix="query")
            return serper_result
        
        # ë‘˜ ë‹¤ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ì¿¼ë¦¬ë¡œ ì¬ì‹œë„ (ìµœëŒ€ 2ë²ˆ)
        print(f"âš ï¸ [ê²€ìƒ‰ ì‹¤íŒ¨] Tavilyì™€ Serper ëª¨ë‘ ì‹¤íŒ¨, ë‹¤ë¥¸ ì¿¼ë¦¬ë¡œ ì¬ì‹œë„...")
        retry_queries = self._generate_retry_queries(query)
        
        for retry_query in retry_queries[:2]:  # ìµœëŒ€ 2ë²ˆë§Œ ì¬ì‹œë„
            if retry_query == query:
                continue  # ì›ë³¸ ì¿¼ë¦¬ëŠ” ì´ë¯¸ ì‹œë„í–ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ
            
            print(f"ğŸ”„ [ì¬ì‹œë„] ì¿¼ë¦¬ ë³€í˜•: {retry_query}")
            
            # Tavilyë¡œ ì¬ì‹œë„
            tavily_retry = await self._search_tavily(retry_query, max_results, "basic")
            if tavily_retry.get("success"):
                print(f"âœ… [ì¬ì‹œë„ ì„±ê³µ] Tavily: {retry_query}")
                research_cache.set(query, tavily_retry, domain="search", prefix="query")
                return tavily_retry
            
            # Serperë¡œ ì¬ì‹œë„
            serper_retry = await self._search_serper(retry_query, max_results)
            if serper_retry.get("success"):
                print(f"âœ… [ì¬ì‹œë„ ì„±ê³µ] Serper: {retry_query}")
                research_cache.set(query, serper_retry, domain="search", prefix="query")
                return serper_retry
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        print(f"âŒ [ê²€ìƒ‰ ì‹¤íŒ¨] ëª¨ë“  ì¿¼ë¦¬ì™€ ì—”ì§„ ì‹¤íŒ¨")
        return {
            "source": "none",
            "results": [],
            "success": False,
            "error": "ëª¨ë“  ê²€ìƒ‰ ì—”ì§„ ë° ì¬ì‹œë„ ì‹¤íŒ¨",
            "query": query
        }
    
    async def _search_with_verification(
        self,
        query: str,
        max_results: int,
        search_depth: str
    ) -> Dict[str, Any]:
        """ê¸°ì¡´ ë©”ì„œë“œ (í•˜ìœ„ í˜¸í™˜ì„±)"""
        return await self._search_with_verification_dynamic(
            query, max_results, search_depth, "basic", min(max_results, 3)
        )
    
    async def _search_tavily_dynamic(
        self,
        query: str,
        max_results: int,
        target_depth: str,
        initial_depth: str,
        initial_max_results: int
    ) -> Dict[str, Any]:
        """ë™ì  ê¹Šì´ ì¡°ì •: basic â†’ intermediate â†’ advanced"""
        # 1ë‹¨ê³„: basicìœ¼ë¡œ ë¹ ë¥´ê²Œ ì‹œë„
        result = await self._search_tavily(query, initial_max_results, initial_depth)
        
        if result.get("success") and len(result.get("results", [])) >= 2:
            return result
        
        # 2ë‹¨ê³„: ê²°ê³¼ ë¶€ì¡± ì‹œ intermediateë¡œ ì¬ì‹œë„
        if initial_depth == "basic" and target_depth in ["intermediate", "advanced"]:
            result = await self._search_tavily(query, max_results, "intermediate")
            if result.get("success") and len(result.get("results", [])) >= 2:
                return result
        
        # 3ë‹¨ê³„: ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ advancedë¡œ ì¬ì‹œë„
        if target_depth == "advanced":
            result = await self._search_tavily(query, max_results, "advanced")
            if result.get("success"):
                return result
        
        return result
    
    def _cross_validate_results(
        self,
        tavily_result: Dict[str, Any],
        ddg_result: Dict[str, Any],
        query: str,
        max_results: int = 5
    ) -> Dict[str, Any]:
        """ë‘ ê²€ìƒ‰ ì—”ì§„ ê²°ê³¼ êµì°¨ ê²€ì¦"""
        
        tavily_results = tavily_result.get("results", []) if tavily_result.get("success") else []
        ddg_results = ddg_result.get("results", []) if ddg_result.get("success") else []
        
        if not tavily_results and not ddg_results:
            return {"success": False, "error": "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"}
        
        # ê³µì‹ ì‚¬ì´íŠ¸ URL íŒ¨í„´
        official_domains = {
            "openai": ["openai.com"],
            "anthropic": ["anthropic.com"],
            "google": ["google.com", "deepmind.google"],
            "gemini": ["gemini.google.com"]
        }
        
        # ê²°ê³¼ í†µí•© ë° ê°€ì¤‘ì¹˜ ê³„ì‚°
        all_results = []
        seen_urls: Set[str] = set()
        
        # 1. ê³µì‹ ì‚¬ì´íŠ¸ ê²°ê³¼ ìš°ì„  (ë†’ì€ ê°€ì¤‘ì¹˜)
        for result in tavily_results + ddg_results:
            url = result.get("url", "").lower()
            if url in seen_urls:
                continue
            
            # ê³µì‹ ì‚¬ì´íŠ¸ í™•ì¸
            is_official = any(
                domain in url for domains in official_domains.values() 
                for domain in domains
            )
            
            # ê°€ì¤‘ì¹˜ ê³„ì‚°
            base_score = result.get("score", 0.5)
            if is_official:
                base_score = min(base_score * 1.5, 1.0)  # ê³µì‹ ì‚¬ì´íŠ¸ +50% ê°€ì¤‘ì¹˜
                print(f"  âœ… ê³µì‹ ì‚¬ì´íŠ¸ ë°œê²¬: {url[:50]}")
            
            result["score"] = base_score
            result["is_official"] = is_official
            all_results.append(result)
            seen_urls.add(url)
        
        # ê°€ê²© ì •ë³´ê°€ í¬í•¨ëœ ê²°ê³¼ ìš°ì„ ìˆœìœ„ ìƒìŠ¹
        pricing_keywords = ["pricing", "cost", "subscription", "plan", "free", "plus", "pro", "$"]
        for result in all_results:
            content = (result.get("title", "") + " " + result.get("content", "")).lower()
            if any(kw in content for kw in pricing_keywords):
                result["score"] = min(result["score"] * 1.2, 1.0)  # ê°€ê²© ì •ë³´ +20% ê°€ì¤‘ì¹˜
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        all_results.sort(key=lambda x: x["score"], reverse=True)
        
        # ìƒìœ„ ê²°ê³¼ë§Œ ë°˜í™˜
        top_results = all_results[:max_results]
        
        return {
            "source": "verified",  # êµì°¨ ê²€ì¦ë¨
            "results": top_results,
            "success": True,
            "query": query,
            "tavily_count": len(tavily_results),
            "ddg_count": len(ddg_results),
            "verified_count": len(top_results)
        }
    
    async def _search_tavily(
        self, 
        query: str, 
        max_results: int,
        search_depth: str
    ) -> Dict[str, Any]:
        """Tavily ê²€ìƒ‰ (íƒ€ì„ì•„ì›ƒ ì ìš©)"""
        try:
            print(f"ğŸ” [Tavily] ê²€ìƒ‰ ì¤‘ ({search_depth}): {query}")
            
            # site: ê²€ìƒ‰ì—ì„œ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
            original_query = query
            if "site:" in query.lower():
                # site: ê²€ìƒ‰ì„ ì‹œë„í•˜ë˜, ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
                pass
            
            # íƒ€ì„ì•„ì›ƒ ì„¤ì •: basic/intermediateëŠ” 8ì´ˆ, advancedëŠ” 12ì´ˆ
            timeout = 8.0 if search_depth in ["basic", "intermediate"] else 12.0
            
            # ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ì ìš©)
            results = await asyncio.wait_for(
                asyncio.to_thread(
                    self.tavily.search,
                    query=query,
                    max_results=max_results,
                    search_depth=search_depth,
                    include_raw_content=False,
                    days=90
                ),
                timeout=timeout
            )
            
            if results and results.get("results"):
                formatted_results = []
                for r in results["results"]:
                    formatted_results.append({
                        "title": r.get("title", ""),
                        "url": r.get("url", ""),
                        "content": r.get("content", ""),
                        "score": r.get("score", 0),
                    })
                
                # í’ˆì§ˆ ê²€ì¦
                if self._validate_results(formatted_results, query):
                    print(f"âœ… [Tavily] {len(formatted_results)}ê°œ ê²°ê³¼ ë°œê²¬ (ê²€ì¦ í†µê³¼)")
                    return {
                        "source": "tavily",
                        "results": formatted_results,
                        "success": True,
                        "query": query
                    }
                else:
                    print(f"âš ï¸ [Tavily] í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨")
                    return {"success": False}
            
            print(f"âš ï¸ [Tavily] ê²°ê³¼ ì—†ìŒ")
            return {"success": False}
        
        except asyncio.TimeoutError:
            print(f"â±ï¸ [Tavily] íƒ€ì„ì•„ì›ƒ ({search_depth})")
            return {"success": False, "timeout": True}
        
        except Exception as e:
            error_str = str(e)
            # 400, 432 ì˜¤ë¥˜ëŠ” site: ê²€ìƒ‰ì—ì„œ ìì£¼ ë°œìƒ
            # TavilyëŠ” site: ê²€ìƒ‰ì„ ì˜ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì‹¤íŒ¨ ì‹œ ë°”ë¡œ Serper.devë¡œ ë„˜ì–´ê°
            # (ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´í•˜ë©´ íŠ¹ì • ì‚¬ì´íŠ¸ ê²€ìƒ‰ ì˜ë„ê°€ ì‚¬ë¼ì§€ë¯€ë¡œ ì˜ë¯¸ ì—†ìŒ)
            if ("site:" in query.lower()) and ("400" in error_str or "432" in error_str or "Bad Request" in error_str):
                print(f"âš ï¸ [Tavily] site: ê²€ìƒ‰ ì˜¤ë¥˜ ({error_str[:50]}), TavilyëŠ” site: ê²€ìƒ‰ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Serper.devë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
            print(f"âŒ [Tavily] ì˜¤ë¥˜: {error_str}")
            return {"success": False}
    
    def _generate_retry_queries(self, original_query: str) -> List[str]:
        """ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„í•  ì¿¼ë¦¬ ëª©ë¡ ìƒì„±"""
        retry_queries = []
        
        # 1. site: ì œê±°í•˜ê³  ì¼ë°˜ ê²€ìƒ‰
        if "site:" in original_query.lower():
            general_query = re.sub(r'site:\S+\s*', '', original_query, flags=re.IGNORECASE).strip()
            if general_query and general_query != original_query:
                retry_queries.append(general_query)
        
        # 2. ì¿¼ë¦¬ë¥¼ ë‹¨ìˆœí™” (íŠ¹ìˆ˜ ë¬¸ì ì œê±°, í‚¤ì›Œë“œë§Œ ì¶”ì¶œ)
        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ë„êµ¬ëª…, í•µì‹¬ ê°œë…)
        keywords = re.findall(r'\b[A-Z][a-zA-Z]+\b', original_query)  # ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë‹¨ì–´
        keywords.extend(re.findall(r'\b\w+\b', original_query.lower()))  # ëª¨ë“  ë‹¨ì–´
        
        # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ê¸°ì¤€ ì •ë¦¬
        keywords = [kw for kw in set(keywords) if len(kw) > 3 and kw.lower() not in ['site', 'pricing', 'features', 'integration']]
        
        if keywords:
            # í•µì‹¬ í‚¤ì›Œë“œë§Œìœ¼ë¡œ ì¿¼ë¦¬ ìƒì„± (ìµœëŒ€ 5ê°œ)
            simplified = ' '.join(keywords[:5])
            if simplified and simplified != original_query.lower():
                retry_queries.append(simplified)
            
            # ë„êµ¬ëª… + "pricing" ë˜ëŠ” "features" ì¡°í•©
            tool_names = [kw for kw in keywords[:3] if kw[0].isupper()]
            if tool_names:
                for suffix in ['pricing', 'features', 'review']:
                    tool_query = f"{' '.join(tool_names)} {suffix}"
                    if tool_query != original_query.lower():
                        retry_queries.append(tool_query)
        
        # 3. ì›ë³¸ ì¿¼ë¦¬ì˜ ì—°ë„ ì œê±° (ì˜ˆ: "2026" ì œê±°)
        year_removed = re.sub(r'\b20\d{2}\b', '', original_query).strip()
        if year_removed and year_removed != original_query:
            retry_queries.append(year_removed)
        
        return retry_queries
    
    async def _search_serper(
        self, 
        query: str, 
        max_results: int
    ) -> Dict[str, Any]:
        """Serper.dev ê²€ìƒ‰ (Google ê²€ìƒ‰ ê²°ê³¼ ì œê³µ, íƒ€ì„ì•„ì›ƒ 5ì´ˆ)"""
        
        if not self.serper_api_key:
            print(f"âŒ [Serper] API í‚¤ ì—†ìŒ")
            return {
                "source": "none",
                "results": [],
                "success": False,
                "error": "Serper API í‚¤ ì—†ìŒ",
                "query": query
            }
        
        try:
            print(f"ğŸ” [Serper] ê²€ìƒ‰ ì¤‘: {query}")
            
            url = "https://google.serper.dev/search"
            headers = {
                'X-API-KEY': self.serper_api_key,
                'Content-Type': 'application/json'
            }
            payload = {
                'q': query,
                'num': max_results
            }
            
            # aiohttpë¡œ ë¹„ë™ê¸° ìš”ì²­ (íƒ€ì„ì•„ì›ƒ 5ì´ˆ)
            async with aiohttp.ClientSession() as session:
                async with session.post(url, headers=headers, json=payload, timeout=5) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # organic ê²°ê³¼ íŒŒì‹±
                        organic_results = data.get('organic', [])
                        
                        if organic_results:
                            formatted_results = [
                                {
                                    "title": r.get("title", ""),
                                    "url": r.get("link", ""),
                                    "content": r.get("snippet", ""),
                                    "score": 0.8,  # SerperëŠ” Google ê²€ìƒ‰ì´ë¼ ë†’ì€ ì ìˆ˜
                                }
                                for r in organic_results[:max_results]
                            ]
                            
                            print(f"âœ… [Serper] {len(formatted_results)}ê°œ ê²°ê³¼ ë°œê²¬")
                            return {
                                "source": "serper",
                                "results": formatted_results,
                                "success": True,
                                "query": query
                            }
                        
                        print(f"âŒ [Serper] ê²°ê³¼ ì—†ìŒ")
                        return {
                            "source": "none",
                            "results": [],
                            "success": False,
                            "error": "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ",
                            "query": query
                        }
                    
                    else:
                        error_text = await response.text()
                        print(f"âŒ [Serper] HTTP {response.status}: {error_text}")
                        return {
                            "source": "none",
                            "results": [],
                            "success": False,
                            "error": f"Serper API ì˜¤ë¥˜: {response.status}",
                            "query": query
                        }
        
        except asyncio.TimeoutError:
            print(f"âŒ [Serper] íƒ€ì„ì•„ì›ƒ")
            return {
                "source": "none",
                "results": [],
                "success": False,
                "error": "Serper íƒ€ì„ì•„ì›ƒ",
                "query": query
            }
        
        except Exception as e:
            print(f"âŒ [Serper] ì˜¤ë¥˜: {str(e)}")
            return {
                "source": "none",
                "results": [],
                "success": False,
                "error": f"Serper ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}",
                "query": query
            }
    
    def _validate_results(self, results: List[Dict], query: str) -> bool:
        """ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ ê²€ì¦ (ì™„í™”ëœ ê¸°ì¤€)"""
        
        # 1. ìµœì†Œ ê²°ê³¼ ê°œìˆ˜ í™•ì¸ (ì™„í™”: 2ê°œ â†’ 1ê°œ)
        if len(results) < 1:
            return False
        
        # 2. ê´€ë ¨ì„± í™•ì¸ (í‚¤ì›Œë“œ ë§¤ì¹­)
        keywords = self._extract_keywords(query)
        if not keywords:
            return True  # í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ í†µê³¼
        
        relevant_count = sum(
            1 for result in results 
            if any(
                kw.lower() in result.get("content", "").lower() 
                or kw.lower() in result.get("title", "").lower()
                for kw in keywords
            )
        )
        
        # ê´€ë ¨ì„± ê¸°ì¤€ ì™„í™” (50% â†’ 30%)
        return relevant_count >= len(results) * 0.3
    
    def _extract_keywords(self, query: str) -> List[str]:
        """ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê³µë°± ê¸°ì¤€)
        words = query.split()
        # 3ê¸€ì ì´ìƒë§Œ
        keywords = [w for w in words if len(w) >= 3]
        return keywords[:5]  # ìµœëŒ€ 5ê°œ
    
    def extract_pricing_info(self, results: List[Dict]) -> Dict[str, Any]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê°€ê²© ì •ë³´ ì¶”ì¶œ ë° ê²€ì¦
        
        ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” ê°€ê²© ì •ë³´ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. 
        - í”Œëœëª…ì€ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‹¤ì œë¡œ ë‚˜ì˜¨ ê²ƒì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (í•˜ë“œì½”ë”© ê¸ˆì§€)
        - ê°œì¸ìš©/ë¹„ì¦ˆë‹ˆìŠ¤ìš© êµ¬ë³„ì€ ì—ì´ì „íŠ¸(LLM)ê°€ ê²€ìƒ‰ ê²°ê³¼ì˜ ì „ì²´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        
        found_pricing = {}
        official_pricing = {}
        
        for result in results:
            # ì›ë³¸ í…ìŠ¤íŠ¸ ìœ ì§€ (ëŒ€ì†Œë¬¸ì êµ¬ë³„)
            title = result.get("title", "")
            content = result.get("content", "")
            full_text = f"{title} {content}"
            url = result.get("url", "").lower()
            is_official = result.get("is_official", False)
            
            # ê°€ê²© íŒ¨í„´ (í”Œëœëª…ì€ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‹¤ì œë¡œ ë‚˜ì˜¨ ê²ƒì„ ì¶”ì¶œ)
            # ì£¼ì˜: í•˜ë“œì½”ë”©ëœ í”Œëœëª…(Free, Pro, Plus ë“±) ì‚¬ìš© ê¸ˆì§€
            pricing_patterns = [
                # í”Œëœëª…ê³¼ ê°€ê²© í•¨ê»˜ (ì˜ˆ: "Pro $10/ì›”", "Pro+ $20/ì›”", "Business $19/ì›”")
                # í”Œëœëª…ì€ ë„êµ¬ë§ˆë‹¤ ë‹¤ë¥´ë¯€ë¡œ í•˜ë“œì½”ë”©í•˜ì§€ ì•Šê³  ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶”ì¶œ
                (r'(?:^|\s)([A-Za-zê°€-í£][A-Za-z0-9ê°€-í£\s\+]*?)\s*\$?\s*(\d+(?:\.\d+)?)\s*/?\s*(?:ì›”|month|mo)', None, None),
                # ì¼ë°˜ ê°€ê²© (ì˜ˆ: "$10/ì›”", "10 USD/ì›”")
                (r'\$(\d+(?:\.\d+)?)\s*/?\s*(?:ì›”|month|mo)', None, None),
                (r'(\d+(?:\.\d+)?)\s*(?:USD|ë‹¬ëŸ¬)\s*/?\s*(?:ì›”|month|mo)', None, None),
                # Free/ë¬´ë£Œ (íŠ¹ë³„ ì²˜ë¦¬)
                (r'(?:^|\s)(?:free|ë¬´ë£Œ)(?:\s|$)', None, "ë¬´ë£Œ"),
            ]
            
            # ê°€ê²© ì •ë³´ ì¶”ì¶œ
            for pattern, default_plan, default_price in pricing_patterns:
                matches = re.finditer(pattern, full_text, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    plan_name = default_plan
                    price = default_price
                    
                    # í”Œëœëª… ë° ê°€ê²© ì¶”ì¶œ
                    groups = match.groups()
                    if default_price is None and len(groups) >= 2:
                        # í”Œëœëª…ê³¼ ê°€ê²© ëª¨ë‘ ìˆëŠ” ê²½ìš°
                        plan_name_match = groups[0].strip()
                        price_match = groups[1]
                        if plan_name_match and price_match:
                            # í”Œëœëª…ì€ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë‚˜ì˜¨ ê·¸ëŒ€ë¡œ ì‚¬ìš© (í•˜ë“œì½”ë”© ê¸ˆì§€)
                            plan_name = plan_name_match
                            price = f"${price_match}/ì›”"
                    elif default_price is None and len(groups) >= 1:
                        # ê°€ê²©ë§Œ ìˆëŠ” ê²½ìš°
                        price_match = groups[0]
                        if price_match:
                            price = f"${price_match}/ì›”"
                            plan_name = None  # í”Œëœëª… ì—†ìŒ
                    elif default_price:
                        # Free/ë¬´ë£Œì¸ ê²½ìš°
                        price = default_price
                        plan_name = "Free"  # FreeëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ë§Œ, ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í™•ì¸ í•„ìš”
                    
                    # ê°€ê²© ì •ë³´ ì €ì¥ (í”Œëœëª…ì´ ìˆìœ¼ë©´ í¬í•¨, ì—†ìœ¼ë©´ ê°€ê²©ë§Œ)
                    if price:
                        # í‚¤ ìƒì„± (í”Œëœëª…ì´ ìˆìœ¼ë©´ í¬í•¨)
                        if plan_name:
                            key = f"{plan_name}_{price}"
                        else:
                            key = f"unknown_{price}"
                        
                        if key not in found_pricing:
                            found_pricing[key] = {
                                "plan": plan_name,  # í”Œëœëª…ì´ ì—†ìœ¼ë©´ None
                                "price": price,
                                "sources": [],
                                "official_count": 0,
                                "context": full_text[:300]  # ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ (ì—ì´ì „íŠ¸ê°€ ê°œì¸ìš©/ë¹„ì¦ˆë‹ˆìŠ¤ìš© íŒë‹¨í•  ìˆ˜ ìˆë„ë¡)
                            }
                        
                        found_pricing[key]["sources"].append({
                            "url": url,
                            "is_official": is_official
                        })
                        
                        if is_official:
                            found_pricing[key]["official_count"] += 1
                            official_pricing[key] = found_pricing[key]
        
        # ê³µì‹ ì‚¬ì´íŠ¸ ê°€ê²© ìš°ì„ 
        if official_pricing:
            return {
                "pricing": list(official_pricing.values()),
                "source": "official",
                "confidence": "high"
            }
        
        # ì—¬ëŸ¬ ì¶œì²˜ì—ì„œ ì¼ì¹˜í•˜ëŠ” ê°€ê²©
        verified_pricing = [
            p for p in found_pricing.values() 
            if len(p["sources"]) >= 2  # 2ê°œ ì´ìƒ ì¶œì²˜ì—ì„œ í™•ì¸
        ]
        
        if verified_pricing:
            return {
                "pricing": verified_pricing,
                "source": "verified",
                "confidence": "medium"
            }
        
        # ë‹¨ì¼ ì¶œì²˜ ê°€ê²©
        if found_pricing:
            return {
                "pricing": list(found_pricing.values()),
                "source": "single",
                "confidence": "low"
            }
        
        return {
            "pricing": [],
            "source": "none",
            "confidence": "none"
        }


# ì „ì—­ ê²€ìƒ‰ ì¸ìŠ¤í„´ìŠ¤
searcher = SearchWithFallback()




"""LLM ê¸°ë°˜ ì¿¼ë¦¬ ì •ê·œí™” - ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì§ˆë¬¸ì„ ê°™ì€ í‚¤ë¡œ ë³€í™˜"""

import hashlib
from typing import Dict, Any, Optional
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage
from pydantic import BaseModel, Field


class NormalizedQuery(BaseModel):
    """ì •ê·œí™”ëœ ì¿¼ë¦¬"""
    normalized_text: str = Field(
        description="ì •ê·œí™”ëœ ì§ˆë¬¸ (í•µì‹¬ ì˜ë„ë§Œ ì¶”ì¶œ, ë™ì¼í•œ ì˜ë¯¸ëŠ” ë™ì¼í•œ í‘œí˜„)"
    )
    keywords: list[str] = Field(
        description="í•µì‹¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ë„êµ¬ëª…, ê¸°ëŠ¥ ë“±)",
        default_factory=list
    )
    intent: str = Field(
        description="ì§ˆë¬¸ ì˜ë„ (comparison, pricing, features, recommendation ë“±)",
        default="general"
    )


NORMALIZATION_PROMPT = """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì •ê·œí™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ëª©í‘œ:** ì˜ë¯¸ì ìœ¼ë¡œ ë™ì¼í•œ ì§ˆë¬¸ë“¤ì„ ë°˜ë“œì‹œ ê°™ì€ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬, ìºì‹œ íˆíŠ¸ìœ¨ì„ ë†’ì…ë‹ˆë‹¤.

**ğŸš¨ í•µì‹¬ ì›ì¹™ (ì ˆëŒ€ ì¤€ìˆ˜!):**
- ë™ì¼í•œ ì˜ë¯¸ = ë™ì¼í•œ keywords = ë™ì¼í•œ normalized_text
- í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ë°˜ë“œì‹œ ë™ì¼í•œ ê²°ê³¼ ìƒì„±
- í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œ í•µì‹¬ë§Œ ì¶”ì¶œí•˜ê³  í‘œí˜„ ì°¨ì´ëŠ” ë¬´ì‹œ

**ì •ê·œí™” í”„ë¡œì„¸ìŠ¤ (ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ!):**

**1ë‹¨ê³„: í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ê·œí™”**
ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ **ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ë‚´ìš©ë§Œ** ì¶”ì¶œí•˜ê³  í†µì¼ëœ ìš©ì–´ë¡œ ë³€í™˜:

1. **ì‘ì—… ìœ í˜•/ì–¸ì–´**: 
   - ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì–¸ì–´/ê¸°ìˆ ë§Œ ì¶”ì¶œ (Python, JavaScript, Java ë“±)
   - "Python ìœ„ì£¼", "Python ê¸°ë°˜", "Pythonìœ¼ë¡œ", "Python" â†’ ëª¨ë‘ "Python"ìœ¼ë¡œ í†µì¼
   - **ì¤‘ìš”**: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•˜ì§€ ì•Šì€ ì–¸ì–´ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”!
   
2. **ì‘ì—… ë‚´ìš©**: 
   - ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì—…ë¬´ ë¶„ì•¼ë§Œ ì¶”ì¶œ
   - "ë°ì´í„° ë¶„ì„", "ë¶„ì„Â·ëª¨ë¸ë§", "ë¶„ì„ ì‘ì—…" â†’ "ë°ì´í„° ë¶„ì„"
   - "ë°±ì—”ë“œ", "í”„ë¡ íŠ¸ì—”ë“œ", "ì›¹ ê°œë°œ", "ì•± ê°œë°œ" â†’ ê·¸ëŒ€ë¡œ ìœ ì§€
   - **ì¤‘ìš”**: "ë°ì´í„° ë¶„ì„"ì´ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”!
   
3. **íŒ€ ê·œëª¨**: 
   - "íŒ€ ë‹¨ìœ„", "íŒ€ìœ¼ë¡œ", "í˜‘ì—…", "íŒ€", "íŒ€ì—ì„œ" â†’ ëª¨ë‘ "íŒ€"ìœ¼ë¡œ í†µì¼
   - íŒ€ ê·œëª¨ ìˆ«ì (8ëª…, 5ëª… ë“±)ê°€ ìˆìœ¼ë©´ í¬í•¨
   
4. **ë„êµ¬ëª… (IDE)**: 
   - "PyCharm", "VS Code" ë“± (ìˆìœ¼ë©´ í¬í•¨, ì—†ìœ¼ë©´ ìƒëµ)
   
5. **ì§ˆë¬¸ ì˜ë„**: 
   - "ì¶”ì²œ", "ì¶”ì²œí•´ì¤˜", "ì¶”ì²œí•´ì£¼ì„¸ìš”", "ì¶”ì²œí•´ë‹¬ë¼" â†’ ëª¨ë‘ "ì¶”ì²œ"ìœ¼ë¡œ í†µì¼

**2ë‹¨ê³„: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ìƒì„±**
- ì¶”ì¶œí•œ í‚¤ì›Œë“œë¥¼ ì•ŒíŒŒë²³ ìˆœì„œë¡œ ì •ë ¬: ["Python", "ë°ì´í„° ë¶„ì„", "íŒ€", "ì½”ë”© AI"]
- ë™ì¼í•œ í‚¤ì›Œë“œ ì¡°í•©ì´ë©´ ë°˜ë“œì‹œ ë™ì¼í•œ ë¦¬ìŠ¤íŠ¸ ìƒì„±

**3ë‹¨ê³„: normalized_text ìƒì„±**
- í‚¤ì›Œë“œë¥¼ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜: [ì‘ì—…ìœ í˜•] [ì‘ì—…ë‚´ìš©] [íŒ€ê·œëª¨] [ì§ˆë¬¸ì˜ë„]
- ì˜ˆ: "Python ë°ì´í„° ë¶„ì„ íŒ€ ì½”ë”© AI ì¶”ì²œ"
- **keywordsê°€ ê°™ìœ¼ë©´ normalized_textë„ ë°˜ë“œì‹œ ë™ì¼í•˜ê²Œ ìƒì„±!**

**ğŸš¨ í•„ìˆ˜ ì˜ˆì‹œ (ë°˜ë“œì‹œ ë™ì¼í•˜ê²Œ ì •ê·œí™”!):**

ì§ˆë¬¸ 1: "PyCharm ì“°ëŠ” ë°ì´í„° ë¶„ì„ íŒ€ì…ë‹ˆë‹¤. Python ìœ„ì£¼ ì‘ì—…ì— ì˜ ë§ê³ , íŒ€ ë‹¨ìœ„ë¡œ ì“°ê¸° ì¢‹ì€ ì½”ë”© AI ì¶”ì²œí•´ì£¼ì„¸ìš”."
â†’ normalized_text: "Python ë°ì´í„° ë¶„ì„ íŒ€ ì½”ë”© AI ì¶”ì²œ"
â†’ keywords: ["Python", "ë°ì´í„° ë¶„ì„", "íŒ€", "ì½”ë”© AI"]

ì§ˆë¬¸ 2: "Python ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„Â·ëª¨ë¸ë§ ì‘ì—…ì„ ë§ì´ í•˜ëŠ” íŒ€ì…ë‹ˆë‹¤. PyCharmì„ ì£¼ë¡œ ì‚¬ìš©í•˜ê³  ìˆê³ , í˜‘ì—…ì— ì˜ ë§ëŠ” ì½”ë”© AI ë„êµ¬ë¥¼ ì¶”ì²œí•´ì¤˜"
â†’ normalized_text: "Python ë°ì´í„° ë¶„ì„ íŒ€ ì½”ë”© AI ì¶”ì²œ"  (ì§ˆë¬¸ 1ê³¼ ë™ì¼!)
â†’ keywords: ["Python", "ë°ì´í„° ë¶„ì„", "íŒ€", "ì½”ë”© AI"]  (ì§ˆë¬¸ 1ê³¼ ë™ì¼!)

ì§ˆë¬¸ 3: "ì €í¬ëŠ” ë°±ì—”ë“œÂ·í”„ë¡ íŠ¸ì—”ë“œ í¬í•¨í•´ì„œ 8ëª… ê·œëª¨ì˜ ê°œë°œíŒ€ì¸ë°, ì½”ë“œ ì‘ì„±ê³¼ ë¦¬ë·°ì— AIë¥¼ ë„ì…í•´ì„œ ìƒì‚°ì„±ì„ ë†’ì´ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–¤ ë„êµ¬ê°€ ì¢‹ì„ê¹Œìš”?"
â†’ normalized_text: "ë°±ì—”ë“œ í”„ë¡ íŠ¸ì—”ë“œ 8ëª… ê°œë°œíŒ€ ì½”ë”© AI ì¶”ì²œ"
â†’ keywords: ["8ëª…", "ê°œë°œíŒ€", "ë°±ì—”ë“œ", "í”„ë¡ íŠ¸ì—”ë“œ", "ì½”ë”© AI"]
â†’ **ì¤‘ìš”**: "ë°ì´í„° ë¶„ì„"ì´ë‚˜ "Python"ì´ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”!

ì§ˆë¬¸ 4: "8ëª… ì •ë„ ë˜ëŠ” ê°œë°œíŒ€ì´ í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œë¥¼ í•¨ê»˜ ê°œë°œí•˜ê³  ìˆëŠ”ë°, ì½”ë”©ê³¼ ì½”ë“œ ë¦¬ë·°ì— ë„ì›€ì´ ë˜ëŠ” AI ë„êµ¬ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ê²Œ ì¢‹ì„ê¹Œìš”?"
â†’ normalized_text: "ë°±ì—”ë“œ í”„ë¡ íŠ¸ì—”ë“œ 8ëª… ê°œë°œíŒ€ ì½”ë”© AI ì¶”ì²œ"  (ì§ˆë¬¸ 3ê³¼ ë™ì¼!)
â†’ keywords: ["8ëª…", "ê°œë°œíŒ€", "ë°±ì—”ë“œ", "í”„ë¡ íŠ¸ì—”ë“œ", "ì½”ë”© AI"]  (ì§ˆë¬¸ 3ê³¼ ë™ì¼!)
â†’ **ì¤‘ìš”**: "í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œ" = "ë°±ì—”ë“œÂ·í”„ë¡ íŠ¸ì—”ë“œ" = "ë°±ì—”ë“œ í”„ë¡ íŠ¸ì—”ë“œ" â†’ ëª¨ë‘ ë™ì¼í•˜ê²Œ ì •ê·œí™”!

ì§ˆë¬¸ 5: "ì§€ê¸ˆ 8ëª… ì •ë„ ë˜ëŠ” ê°œë°œíŒ€ì´ í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œë¥¼ í•¨ê»˜ ê°œë°œí•˜ê³  ìˆëŠ”ë°, ì½”ë”©ê³¼ ì½”ë“œ ë¦¬ë·°ì— ë„ì›€ì´ ë˜ëŠ” AI ë„êµ¬ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ê²Œ ì¢‹ì„ê¹Œìš”?"
â†’ normalized_text: "ë°±ì—”ë“œ í”„ë¡ íŠ¸ì—”ë“œ 8ëª… ê°œë°œíŒ€ ì½”ë”© AI ì¶”ì²œ"  (ì§ˆë¬¸ 3, 4ì™€ ë™ì¼!)
â†’ keywords: ["8ëª…", "ê°œë°œíŒ€", "ë°±ì—”ë“œ", "í”„ë¡ íŠ¸ì—”ë“œ", "ì½”ë”© AI"]  (ì§ˆë¬¸ 3, 4ì™€ ë™ì¼!)
â†’ **ì¤‘ìš”**: "ì§€ê¸ˆ", "ì–´ë–¤ ê²Œ ì¢‹ì„ê¹Œìš”?", "ì–´ë–¤ ë„êµ¬ê°€ ì¢‹ì„ê¹Œìš”?" ê°™ì€ í‘œí˜„ ì°¨ì´ëŠ” ë¬´ì‹œí•˜ê³  í•µì‹¬ë§Œ ì¶”ì¶œ!

**âš ï¸ ì¤‘ìš” ì²´í¬ë¦¬ìŠ¤íŠ¸:**
1. "Python ìœ„ì£¼" = "Python ê¸°ë°˜" = "Python" â†’ ëª¨ë‘ "Python"ìœ¼ë¡œ í†µì¼í–ˆëŠ”ê°€?
2. "ë°ì´í„° ë¶„ì„" = "ë¶„ì„Â·ëª¨ë¸ë§" = "ë¶„ì„ ì‘ì—…" â†’ ëª¨ë‘ "ë°ì´í„° ë¶„ì„"ìœ¼ë¡œ í†µì¼í–ˆëŠ”ê°€?
3. "íŒ€ ë‹¨ìœ„" = "í˜‘ì—…" = "íŒ€" â†’ ëª¨ë‘ "íŒ€"ìœ¼ë¡œ í†µì¼í–ˆëŠ”ê°€?
4. í‚¤ì›Œë“œê°€ ê°™ìœ¼ë©´ normalized_textë„ ë™ì¼í•œê°€?

- "Copilot íšŒì‚¬ì—ì„œ ì¨ë„ ê´œì°®ì•„ìš”?" â†’ "Copilot ê¸°ì—… ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"
- "ê¹ƒí—™ ì½”íŒŒì¼ëŸ¿ ë³´ì•ˆ ë¬¸ì œ ì—†ë‚˜ìš”?" â†’ "Copilot ê¸°ì—… ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"
- "Cursorë‘ Copilot ë­ê°€ ë” ì¢‹ì•„?" â†’ "Cursor Copilot ë¹„êµ"
- "ì»¤ì„œ vs ì½”íŒŒì¼ëŸ¿ ì–´ë–¤ê±° ì¨ì•¼í•´?" â†’ "Cursor Copilot ë¹„êµ"
- "Cursor ê°€ê²©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?" â†’ "Cursor ê°€ê²© ì •ë³´"
- "ì»¤ì„œ ì–¼ë§ˆì—ìš”?" â†’ "Cursor ê°€ê²© ì •ë³´"

**ì…ë ¥:** {user_query}

**ì¶œë ¥ ì „ ìµœì¢… í™•ì¸:**
1. ì´ ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œëŠ” ë¬´ì—‡ì¸ê°€?
2. ì´ í‚¤ì›Œë“œ ì¡°í•©ìœ¼ë¡œ ì´ì „ì— ì •ê·œí™”í•œ ì§ˆë¬¸ì´ ìˆì—ˆëŠ”ê°€?
3. ìˆë‹¤ë©´ â†’ ê·¸ë•Œì™€ ë™ì¼í•œ normalized_textì™€ keywords ì‚¬ìš©
4. ì—†ë‹¤ë©´ â†’ ìƒˆë¡œìš´ ì •ê·œí™” (ë‹¤ìŒì— ê°™ì€ ì˜ë¯¸ ì§ˆë¬¸ì´ ì˜¤ë©´ ì´ ê²°ê³¼ ì¬ì‚¬ìš©)

**ì¶œë ¥ í˜•ì‹:**
- normalized_text: ì •ê·œí™”ëœ ì§ˆë¬¸ (ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ, ë™ì¼í•œ ì˜ë¯¸ëŠ” ë°˜ë“œì‹œ ë™ì¼í•œ í…ìŠ¤íŠ¸)
- keywords: [ì‘ì—…ìœ í˜•, íŒ€ê·œëª¨, ë„êµ¬ëª…, ì§ˆë¬¸ì˜ë„] (ì •ë ¬ëœ ìˆœì„œë¡œ, ë™ì¼í•œ í‚¤ì›Œë“œë©´ ë™ì¼í•œ ë¦¬ìŠ¤íŠ¸)
- intent: ì§ˆë¬¸ ì˜ë„ (comparison / pricing / features / recommendation / security / general)
"""


class QueryNormalizer:
    """ì¿¼ë¦¬ ì •ê·œí™” - ìºì‹œ íˆíŠ¸ìœ¨ í–¥ìƒ"""
    
    def __init__(self, model: str = "gpt-4o-mini", max_tokens: int = 200):
        """
        Args:
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
        """
        self.model_name = model
        self.max_tokens = max_tokens
        self.configurable_model = init_chat_model(
            configurable_fields=("model", "max_tokens", "api_key"),
        )
    
    async def normalize(
        self,
        query: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ ì •ê·œí™”
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            config: LangChain RunnableConfig (API í‚¤ ë“±)
        
        Returns:
            {
                "normalized_text": "ì •ê·œí™”ëœ ì§ˆë¬¸",
                "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
                "intent": "comparison",
                "cache_key": "í•´ì‹œí‚¤"
            }
        """
        try:
            # LLM í˜¸ì¶œ ì„¤ì •
            model_config = config or {
                "model": self.model_name,
                "max_tokens": self.max_tokens,
            }
            
            normalizer_model = (
                self.configurable_model
                .with_structured_output(NormalizedQuery)
                .with_config(model_config)
            )
            
            # ì •ê·œí™” ì‹¤í–‰
            prompt = NORMALIZATION_PROMPT.format(user_query=query)
            response = await normalizer_model.ainvoke([HumanMessage(content=prompt)])
            
            # ìºì‹œ í‚¤ ìƒì„± (ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ + ì •ë ¬ëœ í‚¤ì›Œë“œ ê¸°ë°˜)
            # í‚¤ì›Œë“œë¥¼ ì •ë ¬í•˜ê³  ì†Œë¬¸ìë¡œ í†µì¼í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
            sorted_keywords = sorted([kw.lower().strip() for kw in response.keywords if kw])
            normalized_text_lower = response.normalized_text.lower().strip()
            cache_key_str = f"{normalized_text_lower}:{':'.join(sorted_keywords)}"
            cache_key = hashlib.md5(cache_key_str.encode()).hexdigest()
            
            result = {
                "normalized_text": response.normalized_text,
                "keywords": response.keywords,
                "intent": response.intent,
                "cache_key": cache_key
            }
            
            print(f"âœ… ì¿¼ë¦¬ ì •ê·œí™”: '{query[:50]}...' â†’ '{response.normalized_text}' (ìºì‹œí‚¤: {cache_key[:8]}...)")
            return result
        
        except Exception as e:
            print(f"âš ï¸ ì¿¼ë¦¬ ì •ê·œí™” ì‹¤íŒ¨ (Fallback: ì›ë³¸ ì‚¬ìš©): {e}")
            # Fallback: ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
            cache_key = hashlib.md5(query.lower().strip().encode()).hexdigest()
            return {
                "normalized_text": query,
                "keywords": [],
                "intent": "general",
                "cache_key": cache_key
            }


# ì „ì—­ Normalizer ì¸ìŠ¤í„´ìŠ¤
query_normalizer = QueryNormalizer()


from fastapi import APIRouter, Request
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from langchain_core.messages import HumanMessage
import os
import time

from app.agent.graph import deep_researcher
from app.tools.cache import research_cache


router = APIRouter()
templates = Jinja2Templates(directory="app/templates")


class ChatRequest(BaseModel):
    message: str
    domain: str = "LLM"  # LLM, ì½”ë”©, ë””ìì¸


@router.get("/", response_class=HTMLResponse)
async def index(request: Request):
    return templates.TemplateResponse(
        "index.html",
        {"request": request}
    )


@router.post("/api/chat")
async def chat(req: ChatRequest):
    """AI ì„œë¹„ìŠ¤ ë¹„êµ ë¶„ì„ ì±—ë´‡ API"""
    
    try:
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        
        # 1. ìºì‹œ í™•ì¸
        cached_result = research_cache.get(req.message, req.domain)
        if cached_result:
            elapsed_time = time.time() - start_time
            print(f"âœ… ìºì‹œì—ì„œ ì‘ë‹µ ë°˜í™˜ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            return {"reply": cached_result["reply"]}
        
        # 2. LangGraph ì‹¤í–‰
        print(f"ğŸ” Deep Research ì‹œì‘: {req.message} (ë„ë©”ì¸: {req.domain})")
        
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        openai_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_key or openai_key.startswith("sk-proj-xxx"):
            return {
                "reply": "âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            }
        
        # LangGraph ì‹¤í–‰
        result = await deep_researcher.ainvoke(
            {
                "messages": [HumanMessage(content=req.message)],
                "domain": req.domain
            },
            config={
                "configurable": {
                    "domain": req.domain
                }
            }
        )
        
        # ìµœì¢… ë¦¬í¬íŠ¸ ì¶”ì¶œ
        final_report = result.get("final_report", "")
        
        if not final_report:
            # messagesì—ì„œ ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì¶”ì¶œ
            messages = result.get("messages", [])
            if messages:
                final_report = messages[-1].content
        
        # 3. ìºì‹œ ì €ì¥
        cache_data = {"reply": final_report}
        research_cache.set(req.message, cache_data, req.domain)
        
        # ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
        elapsed_time = time.time() - start_time
        print(f"âœ… Deep Research ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
        
        return {"reply": final_report}
    
    except Exception as e:
        error_msg = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(error_msg)
        return {
            "reply": f"""
ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ë‚´ìš©:**
{str(e)}

**í•´ê²° ë°©ë²•:**
1. .env íŒŒì¼ì— API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
2. ì¸í„°ë„· ì—°ê²° í™•ì¸
3. ì§ˆë¬¸ì„ ë” ê°„ë‹¨í•˜ê²Œ ì‘ì„±í•´ë³´ê¸°

ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
            """
        }